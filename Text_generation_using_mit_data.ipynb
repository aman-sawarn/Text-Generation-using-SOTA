{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text generation using mit data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbbqy4Qn-6BT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "2e4c8db8-1c6a-4eb6-8b3e-628db7fe7525"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import os\n",
        "import math\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import SpatialDropout1D, LSTM, BatchNormalization,concatenate,Flatten,Embedding,Dense,Dropout,MaxPooling2D,Reshape,CuDNNLSTM\n",
        "from keras.models import Sequential\n",
        "from keras import Model,Input\n",
        "from keras.layers.convolutional import Conv2D,Conv1D\n",
        "import keras.backend as k\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from sklearn.utils import compute_class_weight\n",
        "from keras.initializers import he_normal,glorot_normal\n",
        "from keras.regularizers import l1,l2\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint,LearningRateScheduler\n",
        "from time import time\n",
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from IPython.display import SVG, display\n",
        "import pickle \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DAoPUMP-84C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0e791ea-8f96-4acb-9062-4a73bd4004f8"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import requests"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifsWybhF_LP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = requests.get('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7mmDCofAcC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# response.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSM_pQK7AcBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a9df815-d7bf-4daf-cd8e-6c9fb5104be0"
      },
      "source": [
        "data=response.text.split('\\n')\n",
        "data[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is the 100th Etext file presented by Project Gutenberg, and'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRtCYRH7Bkcs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "909d490d-d721-4d46-b5fc-fe0654f3f669"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124457"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrYr26YwBkaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = \" \".join(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3LApdB3CFm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYrE5KSV_PO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(doc):\n",
        "  tokens = doc.split()\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  tokens = [w.translate(table) for w in tokens]\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  tokens = [word.lower() for word in tokens]\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGBXnAAX_Xce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7a92c013-ec4a-4435-e6dc-19b0644d5339"
      },
      "source": [
        "tokens = clean_text(data)\n",
        "print(tokens[:50])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'is', 'the', 'etext', 'file', 'presented', 'by', 'project', 'gutenberg', 'and', 'is', 'presented', 'in', 'cooperation', 'with', 'world', 'library', 'inc', 'from', 'their', 'library', 'of', 'the', 'future', 'and', 'shakespeare', 'cdroms', 'project', 'gutenberg', 'often', 'releases', 'etexts', 'that', 'are', 'not', 'placed', 'in', 'the', 'public', 'domain', 'shakespeare', 'this', 'etext', 'has', 'certain', 'copyright', 'implications', 'you', 'should', 'read']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IL3z-kf_csa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc4597d9-df55-44e2-dba4-99d6d4530f34"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "899788"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAS0EgSHCWGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac879ce5-29f1-43aa-fbb1-8c6c9e181257"
      },
      "source": [
        "len(set(tokens))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28113"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeNaZRE1CZK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5708a833-7ee7-4284-d5be-1c1a550b428c"
      },
      "source": [
        "length = 50 + 1\n",
        "lines = []\n",
        "\n",
        "for i in range(length, len(tokens)):\n",
        "  seq = tokens[i-length:i]\n",
        "  line = ' '.join(seq)\n",
        "  lines.append(line)\n",
        "  if i > 200000:\n",
        "    break\n",
        "\n",
        "print(len(lines))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "199951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3W0QE8MCijN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b46f2e31-d568-4ed8-b386-546aaf7ea05f"
      },
      "source": [
        "lines[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this is the etext file presented by project gutenberg and is presented in cooperation with world library inc from their library of the future and shakespeare cdroms project gutenberg often releases etexts that are not placed in the public domain shakespeare this etext has certain copyright implications you should read this'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_rdxTDJCn3g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d70000f-cdff-4aa1-cec3-41388fbc1ae6"
      },
      "source": [
        "tokens[50]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_g4kKBACqxd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5570f187-baa8-4772-ecf6-17b573849aed"
      },
      "source": [
        "lines[1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'is the etext file presented by project gutenberg and is presented in cooperation with world library inc from their library of the future and shakespeare cdroms project gutenberg often releases etexts that are not placed in the public domain shakespeare this etext has certain copyright implications you should read this electronic'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XvGzlp-Ctip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJV2-eBvCw9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rczJ5yoiCz4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:, :-1], sequences[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIIA0LSeC3Ql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebaaf990-8f32-4eb5-c9c6-b966134ab40a"
      },
      "source": [
        "len(X[10])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Pxz6YuhC9oY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e6b8ef97-142a-4948-acdb-079ef13dc55b"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   22,    11,     1,   397,  2006,  6743,    30,   398,   455,\n",
              "           2,    11,  6743,    10,  6744,    15,   122,   486,   520,\n",
              "          47,    65,   486,     5,     1,  2775,     2,   418, 13163,\n",
              "         398,   455,   678, 13162,  2187,     9,    33,    12,  4811,\n",
              "          10,     1,   848,  3823,   418,    22,   397,   236,   611,\n",
              "         485, 13161,     6,    86,   610])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fm7lxRWDEEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NebEhL08DIav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgVXYiGgDLLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = X.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1mhHyuaDNxu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79377f7a-dbfe-4794-aa40-94b9cde5c3c6"
      },
      "source": [
        "seq_length"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV95OmMZDQl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "3f94f89d-31c1-4a46-c54e-8fd77bffc60c"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkonOgzxDUDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "fe20f6b3-716b-4eec-bcc7-e57c90793ae5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 50)            658250    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 13165)             1329665   \n",
            "=================================================================\n",
            "Total params: 2,138,815\n",
            "Trainable params: 2,138,815\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zredykz1DWmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujZssAebDaWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ce34469-2266-44df-c923-79079526212d"
      },
      "source": [
        "model.fit(X, y, batch_size = 256, epochs = 50)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 199951 samples\n",
            "Epoch 1/50\n",
            "199951/199951 [==============================] - 139s 696us/sample - loss: 6.9053 - acc: 0.0298\n",
            "Epoch 2/50\n",
            "199951/199951 [==============================] - 137s 686us/sample - loss: 6.5710 - acc: 0.0396\n",
            "Epoch 3/50\n",
            "199951/199951 [==============================] - 138s 688us/sample - loss: 6.4226 - acc: 0.0488\n",
            "Epoch 4/50\n",
            "199951/199951 [==============================] - 137s 685us/sample - loss: 6.2382 - acc: 0.0656\n",
            "Epoch 5/50\n",
            "199951/199951 [==============================] - 137s 685us/sample - loss: 6.0880 - acc: 0.0770\n",
            "Epoch 6/50\n",
            "199951/199951 [==============================] - 137s 684us/sample - loss: 5.9705 - acc: 0.0844\n",
            "Epoch 7/50\n",
            "199951/199951 [==============================] - 137s 685us/sample - loss: 5.8694 - acc: 0.0903\n",
            "Epoch 8/50\n",
            "199951/199951 [==============================] - 136s 679us/sample - loss: 5.7745 - acc: 0.0961\n",
            "Epoch 9/50\n",
            "199951/199951 [==============================] - 137s 686us/sample - loss: 5.6834 - acc: 0.1028\n",
            "Epoch 10/50\n",
            "199951/199951 [==============================] - 136s 683us/sample - loss: 5.5979 - acc: 0.1077\n",
            "Epoch 11/50\n",
            "199951/199951 [==============================] - 136s 679us/sample - loss: 5.5185 - acc: 0.1113\n",
            "Epoch 12/50\n",
            "199951/199951 [==============================] - 137s 683us/sample - loss: 5.4424 - acc: 0.1139\n",
            "Epoch 13/50\n",
            "199951/199951 [==============================] - 137s 686us/sample - loss: 5.3690 - acc: 0.1158\n",
            "Epoch 14/50\n",
            "199951/199951 [==============================] - 137s 686us/sample - loss: 5.2992 - acc: 0.1181\n",
            "Epoch 15/50\n",
            "199951/199951 [==============================] - 137s 687us/sample - loss: 5.2299 - acc: 0.1204\n",
            "Epoch 16/50\n",
            "199951/199951 [==============================] - 137s 687us/sample - loss: 5.1625 - acc: 0.1220\n",
            "Epoch 17/50\n",
            "199951/199951 [==============================] - 137s 688us/sample - loss: 5.0969 - acc: 0.1242\n",
            "Epoch 18/50\n",
            "199951/199951 [==============================] - 137s 685us/sample - loss: 5.0347 - acc: 0.1269\n",
            "Epoch 19/50\n",
            "199951/199951 [==============================] - 137s 686us/sample - loss: 4.9754 - acc: 0.1296\n",
            "Epoch 20/50\n",
            "199951/199951 [==============================] - 137s 683us/sample - loss: 4.9182 - acc: 0.1328\n",
            "Epoch 21/50\n",
            "199951/199951 [==============================] - 137s 684us/sample - loss: 4.8655 - acc: 0.1366\n",
            "Epoch 22/50\n",
            "199951/199951 [==============================] - 137s 683us/sample - loss: 4.8143 - acc: 0.1398\n",
            "Epoch 23/50\n",
            "199951/199951 [==============================] - 136s 683us/sample - loss: 4.7648 - acc: 0.1440\n",
            "Epoch 24/50\n",
            "199951/199951 [==============================] - 136s 678us/sample - loss: 4.7198 - acc: 0.1480\n",
            "Epoch 25/50\n",
            "199951/199951 [==============================] - 136s 678us/sample - loss: 4.6783 - acc: 0.1517\n",
            "Epoch 26/50\n",
            "199951/199951 [==============================] - 135s 677us/sample - loss: 4.6374 - acc: 0.1550\n",
            "Epoch 27/50\n",
            "199951/199951 [==============================] - 136s 679us/sample - loss: 4.5990 - acc: 0.1590\n",
            "Epoch 28/50\n",
            "199951/199951 [==============================] - 136s 680us/sample - loss: 4.5612 - acc: 0.1633\n",
            "Epoch 29/50\n",
            "199951/199951 [==============================] - 135s 673us/sample - loss: 4.5240 - acc: 0.1671\n",
            "Epoch 30/50\n",
            "199951/199951 [==============================] - 135s 677us/sample - loss: 4.4914 - acc: 0.1698\n",
            "Epoch 31/50\n",
            "199951/199951 [==============================] - 134s 671us/sample - loss: 4.4572 - acc: 0.1737\n",
            "Epoch 32/50\n",
            "199951/199951 [==============================] - 134s 672us/sample - loss: 4.4259 - acc: 0.1765\n",
            "Epoch 33/50\n",
            "199951/199951 [==============================] - 135s 674us/sample - loss: 4.3949 - acc: 0.1790\n",
            "Epoch 34/50\n",
            "199951/199951 [==============================] - 135s 674us/sample - loss: 4.3651 - acc: 0.1825\n",
            "Epoch 35/50\n",
            "199951/199951 [==============================] - 135s 676us/sample - loss: 4.3361 - acc: 0.1854\n",
            "Epoch 36/50\n",
            "199951/199951 [==============================] - 135s 676us/sample - loss: 4.3049 - acc: 0.1900\n",
            "Epoch 37/50\n",
            "199951/199951 [==============================] - 134s 669us/sample - loss: 4.2790 - acc: 0.1924\n",
            "Epoch 38/50\n",
            "199951/199951 [==============================] - 135s 674us/sample - loss: 4.2493 - acc: 0.1962\n",
            "Epoch 39/50\n",
            "199951/199951 [==============================] - 135s 676us/sample - loss: 4.2236 - acc: 0.1988\n",
            "Epoch 40/50\n",
            "199951/199951 [==============================] - 135s 674us/sample - loss: 4.1955 - acc: 0.2026\n",
            "Epoch 41/50\n",
            "199951/199951 [==============================] - 134s 671us/sample - loss: 4.1695 - acc: 0.2054\n",
            "Epoch 42/50\n",
            "199951/199951 [==============================] - 135s 673us/sample - loss: 4.1446 - acc: 0.2077\n",
            "Epoch 43/50\n",
            "199951/199951 [==============================] - 134s 672us/sample - loss: 4.1170 - acc: 0.2111\n",
            "Epoch 44/50\n",
            "199951/199951 [==============================] - 135s 676us/sample - loss: 4.0933 - acc: 0.2147\n",
            "Epoch 45/50\n",
            "199951/199951 [==============================] - 135s 676us/sample - loss: 4.0699 - acc: 0.2176\n",
            "Epoch 46/50\n",
            "199951/199951 [==============================] - 135s 675us/sample - loss: 4.0427 - acc: 0.2208\n",
            "Epoch 47/50\n",
            "199951/199951 [==============================] - 135s 675us/sample - loss: 4.0202 - acc: 0.2234\n",
            "Epoch 48/50\n",
            "199951/199951 [==============================] - 136s 679us/sample - loss: 3.9976 - acc: 0.2254\n",
            "Epoch 49/50\n",
            "199951/199951 [==============================] - 137s 686us/sample - loss: 3.9727 - acc: 0.2299\n",
            "Epoch 50/50\n",
            "199951/199951 [==============================] - 136s 681us/sample - loss: 3.9496 - acc: 0.2323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7fc3ee4710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30OX7nQqDeJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text='' + lines[12343]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbMjRhbeDv5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "  text = []\n",
        "\n",
        "  for _ in range(n_words):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "\n",
        "    y_predict = model.predict_classes(encoded)\n",
        "\n",
        "    predicted_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == y_predict:\n",
        "        predicted_word = word\n",
        "        break\n",
        "    seed_text = seed_text + ' ' + predicted_word\n",
        "    text.append(predicted_word)\n",
        "  return ' '.join(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu0eFYshFQdw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4013d81f-5645-4a73-b0fc-93a9a9039389"
      },
      "source": [
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 100)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i am forsaken a earthly infectious retreat and perfumd up a skull with tokens and faces by sea and seas as added with all the milky head of reverend priam are not so cut to violate my name is bent to thee and thou art all the tuned spheres and the king of the world and usurper of the world and power of all the world and raild of thence unthrifty loveliness i am awake hangings with the judicious grieve the truth and displeasure and i have seen dwellers on books and colours and station and running grown to the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLdv8bgEFUTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5f1ddb60-4dcc-4b25-fe88-867e6ca66726"
      },
      "source": [
        "seed_text"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cannot dispraise but in a kind of praise naming thy name blesses an ill report o what a mansion have those vices got which for their habitation chose out thee where beautys veil doth cover every blot and all things turns to fair that eyes can see take heed dear heart'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWHoKsjDFXyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(1024, return_sequences=True))\n",
        "model.add(LSTM(1024))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6siYvbmxFybb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_80wV1QF2U7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X, y, batch_size = 256, epochs = 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ-O8tz7F51K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}